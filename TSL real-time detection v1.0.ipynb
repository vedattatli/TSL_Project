{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26ed001-3a39-42d6-b201-bc3fcff31ec9",
   "metadata": {},
   "source": [
    "## Gerekli kütüphaneleri import et\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b463ef-d11d-46cb-8af5-02214c01fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d7ff7-2187-44d2-be6c-b20ae267320d",
   "metadata": {},
   "source": [
    "## actions listesini oluştur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349900d3-573b-42b3-b929-987c7e3bb29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam hareket sayısı: 8\n",
      "['A' 'B' 'C' 'MERHABA' 'TESSEKKUR' 'NASIL_SIN' 'EVET' 'HAYIR']\n"
     ]
    }
   ],
   "source": [
    "# Tanıyacağımız işaretler (örnekle başlıyoruz)\n",
    "actions = np.array([\n",
    "    'A','B','C',  # Türkçe alfabedeki harfler (Ç,Ğ,İ,Ö,Ş,Ü dahil)\n",
    "    'MERHABA','TESSEKKUR','NASIL_SIN','EVET','HAYIR'\n",
    "])\n",
    "\n",
    "print(f\"Toplam hareket sayısı: {len(actions)}\")\n",
    "print(actions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a757c54-ae0a-487a-b6ee-2a77007e72ce",
   "metadata": {},
   "source": [
    "## Model Kodunu Actions Listesine Göre Güncelleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f973c2-4174-416d-ae84-2efb6ebabe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vedat-Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">442,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │         \u001b[38;5;34m442,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m98,816\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">549,704</span> (2.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m549,704\u001b[0m (2.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">549,704</span> (2.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m549,704\u001b[0m (2.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Daha önce tanımladığımız actions dizisi burada kullanılacak\n",
    "# actions = np.array([...])\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(64, return_sequences=True, input_shape=(30, 1662)),\n",
    "    layers.LSTM(128, return_sequences=False),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(actions), activation='softmax')  # çıktı katmanını actions sayısına göre ayarlıyoruz\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49307c-1274-4fb7-8342-b245c4c24716",
   "metadata": {},
   "source": [
    "***********************************\n",
    "***********************************\n",
    "***********************************\n",
    "# Adım 3: Video-Temelli Veri Toplama\n",
    "***********************************\n",
    "***********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ccf9a65-2b2b-472f-8bf0-f4b9468f8b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kütüphaneler\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c045c-23b5-4fb8-89b3-abf001f060a1",
   "metadata": {},
   "source": [
    "### Parametreleri Tanımlayın"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d722e9-e968-4709-a189-f7846ffda431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ——— Ayarlar ———\n",
    "label = 'MERHABA'           # Kaydedeceğiniz işaretin adı\n",
    "num_sequences = 30          # Her işaret için video/sekan sayısı\n",
    "sequence_length = 30        # Her sekanstaki kare (frame) sayısı\n",
    "\n",
    "DATA_PATH = os.path.join('MP_Data', label)\n",
    "#label’i her seferinde farklı işarette (örn. 'A', 'B', 'TESSEKKUR') çalıştırarak değiştirin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7aef1-0f53-4003-8012-f880178562bf",
   "metadata": {},
   "source": [
    "### Klasörleri Oluşturun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684e6c18-3a5d-4d3c-893d-c12fb2cbb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her sequence için klasör\n",
    "for seq in range(num_sequences):\n",
    "    dir_path = os.path.join(DATA_PATH, str(seq))\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    #Çalıştırınca MP_Data/MERHABA/0 … MP_Data/MERHABA/29 klasörleri oluşacak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffba1c0-e772-4893-b54b-ff4402c47dd2",
   "metadata": {},
   "source": [
    "### Mediapipe Holistic Kurulumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b8a5c4-f415-4029-bc44-695a968c4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f51cd-1e41-4607-a1c6-bbac6ddba869",
   "metadata": {},
   "source": [
    "### Video Yakalama ve Landmark Çıkarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae0b56-887c-4774-a4ab-20970ca3f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "for seq in range(num_sequences):\n",
    "    for frame_num in range(sequence_length):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # RGB’ya çevir ve işle\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = mp_holistic.process(image)\n",
    "\n",
    "        # Landmark’ları tek bir vektöre dönüştür\n",
    "        keypoints = []\n",
    "        # Vücut\n",
    "        if results.pose_landmarks:\n",
    "            for lm in results.pose_landmarks.landmark:\n",
    "                keypoints += [lm.x, lm.y, lm.z, lm.visibility]\n",
    "        else:\n",
    "            keypoints += [0]*132   # 33 landmark ×4\n",
    "\n",
    "        # Sol el\n",
    "        if results.left_hand_landmarks:\n",
    "            for lm in results.left_hand_landmarks.landmark:\n",
    "                keypoints += [lm.x, lm.y, lm.z]\n",
    "        else:\n",
    "            keypoints += [0]*63    # 21 landmark ×3\n",
    "\n",
    "        # Sağ el\n",
    "        if results.right_hand_landmarks:\n",
    "            for lm in results.right_hand_landmarks.landmark:\n",
    "                keypoints += [lm.x, lm.y, lm.z]\n",
    "        else:\n",
    "            keypoints += [0]*63\n",
    "\n",
    "        # (İstersen yüz landmark’larını da ekleyebilirsin)\n",
    "\n",
    "        # Kaydet\n",
    "        npy_path = os.path.join(DATA_PATH, str(seq), f\"{frame_num}.npy\")\n",
    "        np.save(npy_path, np.array(keypoints))\n",
    "\n",
    "        # Görüntü ekranda\n",
    "        cv2.putText(frame, f'{label} {seq}-{frame_num}', (10,30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        cv2.imshow('Recording', frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Kod çalışırken ekranda “label sekan frame” bilgisi gözükecek.\n",
    "#q ile erken çıkabilirsiniz; normalde tüm kareleri kaydedecektir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db48b2ba-6705-43a3-a879-4854fc6a2f25",
   "metadata": {},
   "source": [
    "### Kayıtların Kontrolü\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaf08b74-b48d-4f0f-98ac-e4bdfcd74e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MP_Data\\\\MERHABA\\\\0\\\\0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# İlk .npy dosyasını yükleyip boyutunu kontrol et\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mopen\u001b[39m(os_fspath(file), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MP_Data\\\\MERHABA\\\\0\\\\0.npy'"
     ]
    }
   ],
   "source": [
    "# Örnek: 0. sekansın dosyalarını listele\n",
    "print(os.listdir(os.path.join(DATA_PATH, '0')))\n",
    "# İlk .npy dosyasını yükleyip boyutunu kontrol et\n",
    "arr = np.load(os.path.join(DATA_PATH, '0', '0.npy'))\n",
    "print(arr.shape)\n",
    "\n",
    "#print 1662 (4×33 + 3×21 + 3×21) gibi sabit bir boyut göstermeli.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0007225-f5e7-479b-9cd5-15b7a1d9f7f2",
   "metadata": {},
   "source": [
    "***********************************\n",
    "***********************************\n",
    "***********************************\n",
    "# Adım 4: Modeli Yeniden Eğitme\n",
    "***********************************\n",
    "***********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5303a08-dc6a-44b1-8b51-1c4c5568d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, utils\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa6552a-fff1-4de4-acbd-1ad66e36f43c",
   "metadata": {},
   "source": [
    "### actions Dizisini ve Veri Yolunu Tanımlayın"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae63ae6-99ab-49ca-bed1-aaef63de9a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Tanımlı hareketler (Adım 2’de oluşturduğunuz liste)\n",
    "actions = np.array([\n",
    "    'A','B','C',  # … tüm harfler\n",
    "    'MERHABA','TESSEKKUR','NASIL_SIN','EVET','HAYIR'\n",
    "])\n",
    "\n",
    "# 2) Veri klasörü\n",
    "DATA_PATH = 'MP_Data'\n",
    "\n",
    "#actions listesinin birebir Adım 2’dekiyle aynı olduğuna emin olun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e265cc5c-002c-4cb4-8e88-3903a820cd25",
   "metadata": {},
   "source": [
    "### Veriyi Yükleyip X, y Dizilerine Dönüştürme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3577f5ec-93b7-4f1f-8a2e-6b1586b6b96e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Sistem belirtilen yolu bulamıyor: 'MP_Data\\\\A'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m action_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATA_PATH, action)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# her hareketin sekans numaraları\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(action_path), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m      9\u001b[0m     window \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m     seq_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(action_path, seq)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Sistem belirtilen yolu bulamıyor: 'MP_Data\\\\A'"
     ]
    }
   ],
   "source": [
    "# Burada her klasör (hareket) için alt klasörleri (sekans) dolaşıp, içindeki .npy dosyalarını okuyoruz:\n",
    "\n",
    "sequences, labels = [], []\n",
    "\n",
    "for idx, action in enumerate(actions):\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    # her hareketin sekans numaraları\n",
    "    for seq in sorted(os.listdir(action_path), key=int):\n",
    "        window = []\n",
    "        seq_path = os.path.join(action_path, seq)\n",
    "        # her kare\n",
    "        for frame_num in sorted(os.listdir(seq_path), key=int):\n",
    "            frame_path = os.path.join(seq_path, frame_num)\n",
    "            res = np.load(frame_path)               # (1662,) vektör\n",
    "            window.append(res)\n",
    "        sequences.append(window)                   # (30,1662)\n",
    "        labels.append(idx)                         # one-hot için indeks\n",
    "\n",
    "# numpy array’ine çevir\n",
    "X = np.array(sequences)                          # shape: (num_samples, 30, 1662)\n",
    "y = utils.to_categorical(labels).astype(int)     # shape: (num_samples, num_actions)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# X.shape örneğin (N, 30, 1662); y.shape ise (N, len(actions)) olmalı."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02feba-5349-44d6-8553-82814bfb070c",
   "metadata": {},
   "source": [
    "### Eğitim ve Test Setine Ayırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "845ef294-2e8f-4262-876e-e0c2bec57db6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Veriyi %80 eğitim, %20 test olarak bölüyoruz:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m----> 4\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Veriyi %80 eğitim, %20 test olarak bölüyoruz:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test set:  {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# stratify=y ile her sınıftan dengeli örnek ayırmış oluruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7813a35-97a5-4725-902b-72b1c1b5e8e8",
   "metadata": {},
   "source": [
    "### Model Mimarisi Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628a3801-7a02-4bc3-aa1f-2471ad6fe2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vedat-Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">442,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │         \u001b[38;5;34m442,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m98,816\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">549,704</span> (2.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m549,704\u001b[0m (2.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">549,704</span> (2.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m549,704\u001b[0m (2.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aşağıdaki LSTM → Dense mimarisini kullanıyoruz:\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(64, return_sequences=True, input_shape=(30, 1662)),\n",
    "    layers.LSTM(128, return_sequences=False),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#Son katman len(actions) siniflı softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de79f3-4839-4d31-854f-b0d230e85ce8",
   "metadata": {},
   "source": [
    "### Modeli Derleme ve Eğitme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df0c42f-b91c-47d5-9d6a-017a88780a81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compile ve fit:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      4\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m---> 10\u001b[0m     X_train, y_train,\n\u001b[0;32m     11\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,                     \u001b[38;5;66;03m# İhtiyaca göre artırabilirsiniz\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     13\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test)\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Compile ve fit:\n",
    "\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,                     # İhtiyaca göre artırabilirsiniz\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "\n",
    "# Eğitim süresince loss ve accuracy değerlerini izleyin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0687776-b5da-41ed-9fb1-20258b461ad2",
   "metadata": {},
   "source": [
    "### Eğitim Sonrası Modeli Kaydetme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9170fd44-e8e8-4fd6-8986-eed6c1b3c6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kaydedildi: tsl_action_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.save('tsl_action_model.h5')\n",
    "print(\"Model kaydedildi: tsl_action_model.h5\")\n",
    "\n",
    "#Bu dosyayı ileride gerçek-zamanlı tahmin için yükleyeceğiz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0a3b0-2d2d-43fe-8368-fc4a7aa044bf",
   "metadata": {},
   "source": [
    "### Eğitim Grafiğini Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a8ad87-bcbd-4dd3-b034-e34370eb2dec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loss\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Eğrisi')\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Eğrisi')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53028c26-5d87-4829-844b-62a9f6c55c69",
   "metadata": {},
   "source": [
    "***********************************\n",
    "***********************************\n",
    "***********************************\n",
    "# Adım 5: Tahmin Mantığı ve Cümle oluşturma\n",
    "***********************************\n",
    "***********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b55ab388-4157-46e0-9b0e-abcad2cc9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import mediapipe as mp\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177ca8a-5f7b-4155-84c0-0e6144c4d218",
   "metadata": {},
   "source": [
    "### Modeli ve Ayarları Yükle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d9e299-8446-4057-9599-8b76c11d964a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# 1) Eğittiğiniz modeli yükleyin\n",
    "model = load_model('tsl_action_model.h5')\n",
    "\n",
    "# 2) Hareket listesi (Adım 2’dekilerle aynı)\n",
    "actions = ['A','B','C','MERHABA','TESSEKKUR','NASIL_SIN','EVET','HAYIR']\n",
    "\n",
    "# 3) Sıralı kareleri tutmak için pencere boyutu\n",
    "sequence_length = 30\n",
    "threshold = 0.7    # olasılık eşiği\n",
    "\n",
    "# 4) Kaymayı kolaylaştırmak için deque (fixed-length queue)\n",
    "seq_deque = deque(maxlen=sequence_length)\n",
    "predictions = deque(maxlen=10)  # son 10 tahmini tutalım\n",
    "sentence = []                   # oluşturduğumuz metin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71201f4-db8b-432a-ad02-193cdd6b55ea",
   "metadata": {},
   "source": [
    "### Mediapipe Holistic Kurulumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9677b6fe-45cb-4e2f-9020-d19896dd0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic.Holistic(\n",
    "    static_image_mode=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa272f-118b-4986-8aa6-d860e5198c82",
   "metadata": {},
   "source": [
    "### Gerçek-Zamanlı Döngü ve Landmark Çıkarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66562933-c20b-4f91-8c17-02eb48e4df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # 1) Kareyi RGB’ye çevir ve işle\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = mp_holistic.process(image)\n",
    "\n",
    "    # 2) Landmark vector oluştur\n",
    "    keypoints = []\n",
    "    # Pose\n",
    "    if results.pose_landmarks:\n",
    "        for lm in results.pose_landmarks.landmark:\n",
    "            keypoints += [lm.x, lm.y, lm.z, lm.visibility]\n",
    "    else:\n",
    "        keypoints += [0]*132\n",
    "    # Sol el\n",
    "    if results.left_hand_landmarks:\n",
    "        for lm in results.left_hand_landmarks.landmark:\n",
    "            keypoints += [lm.x, lm.y, lm.z]\n",
    "    else:\n",
    "        keypoints += [0]*63\n",
    "    # Sağ el\n",
    "    if results.right_hand_landmarks:\n",
    "        for lm in results.right_hand_landmarks.landmark:\n",
    "            keypoints += [lm.x, lm.y, lm.z]\n",
    "    else:\n",
    "        keypoints += [0]*63\n",
    "\n",
    "    # 3) deque’ye ekle\n",
    "    seq_deque.append(keypoints)\n",
    "    if len(seq_deque) < sequence_length:\n",
    "        # yeterli kare toplanana kadar bekle\n",
    "        cv2.putText(frame, 'Hazırlanıyor...', (10,60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('TSL Tahmin', frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    # 4) Model tahmini\n",
    "    res = model.predict(np.expand_dims(seq_deque, axis=0))[0]  # (len(actions),)\n",
    "    predicted_id = np.argmax(res)\n",
    "    predicted_action = actions[predicted_id]\n",
    "    confidence = res[predicted_id]\n",
    "\n",
    "    # 5) Tahminleri yumuşatma\n",
    "    predictions.append(predicted_id)\n",
    "    # Son 10 tahminin hepsi aynı mı?\n",
    "    if predictions.count(predicted_id) == predictions.maxlen and confidence > threshold:\n",
    "        # Yeni kelime ekle (art arda eklemeyi engelle)\n",
    "        if len(sentence) == 0 or sentence[-1] != predicted_action:\n",
    "            sentence.append(predicted_action)\n",
    "\n",
    "    # 6) Ekrana yazdır\n",
    "    cv2.rectangle(frame, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "    cv2.putText(frame, ' '.join(sentence), (3,30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "    # 7) Görüntüyü göster\n",
    "    cv2.imshow('TSL Tahmin', frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d45b27-696c-4d2d-a762-bef54b09eda5",
   "metadata": {},
   "source": [
    "***********************************\n",
    "***********************************\n",
    "***********************************\n",
    "# Adım 6: Optimizasyon Test\n",
    "***********************************\n",
    "***********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62de17b-b8c9-4020-b657-374b96527554",
   "metadata": {},
   "source": [
    "### Performans Profili ve Zaman Analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7786eb68-a5c4-4390-8d8f-5e6791ee2c1e",
   "metadata": {},
   "source": [
    "#### 1. Kod Profiler Kullanımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cdaf2f9-47b3-418a-a977-36b55340899f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2305580248.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    python -m cProfile -s time 5_predict_sentence.py\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "# Python’da cProfile modülünü kullanarak eğitim ve tahmin adımlarının zamanını ölçün:\n",
    "python -m cProfile -s time 5_predict_sentence.py\n",
    "# En çok zaman alan fonksiyonları tespit edin (örn. model.predict, Mediapipe.process)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f8784f-8296-41c2-b271-9fa609c7c5e4",
   "metadata": {},
   "source": [
    "#### 2.Frame Rate (FPS) Ölçümü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8df061fc-e907-4377-b172-550d137dc632",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      4\u001b[0m frame_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# … mevcut kodunuz …\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     frame_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frame_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m30\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cap' is not defined"
     ]
    }
   ],
   "source": [
    "#while döngüsüne sayaç ekleyin:\n",
    "import time\n",
    "start = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    # … mevcut kodunuz …\n",
    "    frame_count += 1\n",
    "    if frame_count == 30:\n",
    "        end = time.time()\n",
    "        print(f\"FPS: {30/(end-start):.2f}\")\n",
    "        start, frame_count = time.time(), 0\n",
    "\n",
    "# 30 kare üzerinden FPS’i ölçün; hedefiniz en az 10–15 FPS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1933ab94-eb15-4a9a-8b27-befd01ce02b5",
   "metadata": {},
   "source": [
    "### Model Optimizasyonu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a4795-17b7-4c66-8137-62690c9d2105",
   "metadata": {},
   "source": [
    "#### 1.Dropout ve Katman Genişlik Ayarı\n",
    "\n",
    "%30 dropout’u %20–%40 arasında deneyin.\n",
    "\n",
    "LSTM(128) veya LSTM(64) gibi nöron sayısını değiştirin.\n",
    "\n",
    "#### 2.Eğitim Ayarları\n",
    "\n",
    "batch_size=16 / 32 / 64 ile eğitim tekrarları yapın.\n",
    "\n",
    "epochs sayısını 50–200 arasında ayarlayıp overfitting’i kontrol edin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca335ef-6600-4e3b-9565-9a200d1e3709",
   "metadata": {},
   "source": [
    "#### 3.Veri Augmentasyon\n",
    "\n",
    "Tam kareler yerine elleri içeren kareleri kırpıp ölçeklendirin.\n",
    "\n",
    "Işık koşullarını simüle etmek için parlaklık/kontrast varyasyonları ekleyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2449b73-4588-4090-8c4f-aab637b9ddba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Karanlık & parlak versiyon\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m image_aug \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mconvertScaleAbs(frame, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.2\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frame' is not defined"
     ]
    }
   ],
   "source": [
    "# Karanlık & parlak versiyon\n",
    "image_aug = cv2.convertScaleAbs(frame, alpha=1.2, beta=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974fa221-e1ab-4063-94a7-3cd911e2db4f",
   "metadata": {},
   "source": [
    "### TensorFlow Lite Dönüşümü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4c8e008-ca5c-40cb-a830-262167c5dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Vedat-Dell\\AppData\\Local\\Temp\\tmpztrsj5l0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Vedat-Dell\\AppData\\Local\\Temp\\tmpztrsj5l0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\Vedat-Dell\\AppData\\Local\\Temp\\tmpztrsj5l0'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 30, 1662), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1386371644112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1386371644880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1386371645072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1386372481488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1386372483024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1386372483600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1386372481680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1386372484368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1386372483408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1386372485712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"sequential_1/lstm_1/TensorArrayV2_1@__inference_function_1024\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_1075\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"sequential_1/lstm_1/TensorArrayV2_1@__inference_function_1024\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_1075\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)\n\u001b[0;32m     10\u001b[0m converter\u001b[38;5;241m.\u001b[39moptimizations \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mOptimize\u001b[38;5;241m.\u001b[39mDEFAULT]\n\u001b[1;32m---> 11\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Dosyayı kaydet\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsl_action_model.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1250\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1249\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_and_export_metrics(convert_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1202\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[0;32m   1201\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[1;32m-> 1202\u001b[0m result \u001b[38;5;241m=\u001b[39m convert_func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1203\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1768\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;129m@_export_metrics\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a keras model based on instance variables.\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \n\u001b[0;32m   1759\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;124;03m      Invalid quantization parameters.\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m   saved_model_convert_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_as_saved_model()\n\u001b[0;32m   1769\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[0;32m   1770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1749\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1745\u001b[0m   graph_def, input_tensors, output_tensors \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1746\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_keras_to_saved_model(temp_dir)\n\u001b[0;32m   1747\u001b[0m   )\n\u001b[0;32m   1748\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_dir:\n\u001b[1;32m-> 1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(TFLiteKerasModelConverterV2, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[0;32m   1750\u001b[0m         graph_def, input_tensors, output_tensors\n\u001b[0;32m   1751\u001b[0m     )\n\u001b[0;32m   1752\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1753\u001b[0m   shutil\u001b[38;5;241m.\u001b[39mrmtree(temp_dir, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1487\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2.convert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m   1480\u001b[0m   logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1481\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing new converter: If you encounter a problem \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1482\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease file a bug. You can opt-out \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1483\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby setting experimental_new_converter=False\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1484\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;66;03m# Converts model.\u001b[39;00m\n\u001b[1;32m-> 1487\u001b[0m result \u001b[38;5;241m=\u001b[39m _convert_graphdef(\n\u001b[0;32m   1488\u001b[0m     input_data\u001b[38;5;241m=\u001b[39mgraph_def,\n\u001b[0;32m   1489\u001b[0m     input_tensors\u001b[38;5;241m=\u001b[39minput_tensors,\n\u001b[0;32m   1490\u001b[0m     output_tensors\u001b[38;5;241m=\u001b[39moutput_tensors,\n\u001b[0;32m   1491\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconverter_kwargs,\n\u001b[0;32m   1492\u001b[0m )\n\u001b[0;32m   1494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_tflite_model(\n\u001b[0;32m   1495\u001b[0m     result,\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quant_mode,\n\u001b[0;32m   1497\u001b[0m     _build_conversion_flags(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconverter_kwargs)\u001b[38;5;241m.\u001b[39mdebug_options,\n\u001b[0;32m   1498\u001b[0m     quant_io\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_new_quantizer,\n\u001b[0;32m   1499\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:212\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     report_error_message(\u001b[38;5;28mstr\u001b[39m(converter_error))\n\u001b[1;32m--> 212\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m converter_error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Re-throws the exception.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:885\u001b[0m, in \u001b[0;36mconvert_graphdef\u001b[1;34m(input_data, input_tensors, output_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    883\u001b[0m     model_flags\u001b[38;5;241m.\u001b[39moutput_arrays\u001b[38;5;241m.\u001b[39mappend(util\u001b[38;5;241m.\u001b[39mget_tensor_name(output_tensor))\n\u001b[1;32m--> 885\u001b[0m data \u001b[38;5;241m=\u001b[39m convert(\n\u001b[0;32m    886\u001b[0m     model_flags,\n\u001b[0;32m    887\u001b[0m     conversion_flags,\n\u001b[0;32m    888\u001b[0m     input_data\u001b[38;5;241m.\u001b[39mSerializeToString(),\n\u001b[0;32m    889\u001b[0m     debug_info_str\u001b[38;5;241m=\u001b[39mdebug_info\u001b[38;5;241m.\u001b[39mSerializeToString() \u001b[38;5;28;01mif\u001b[39;00m debug_info \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\convert.py:350\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(model_flags, conversion_flags, input_data_str, debug_info_str)\u001b[0m\n\u001b[0;32m    343\u001b[0m     conversion_flags\u001b[38;5;241m.\u001b[39mguarantee_all_funcs_one_use \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert(\n\u001b[0;32m    345\u001b[0m         model_flags,\n\u001b[0;32m    346\u001b[0m         conversion_flags,\n\u001b[0;32m    347\u001b[0m         input_data_str,\n\u001b[0;32m    348\u001b[0m         debug_info_str,\n\u001b[0;32m    349\u001b[0m     )\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m converter_error\n",
      "\u001b[1;31mConverterError\u001b[0m: <unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"sequential_1/lstm_1/TensorArrayV2_1@__inference_function_1024\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_1075\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"sequential_1/lstm_1/TensorArrayV2_1@__inference_function_1024\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper_1075\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\\n converter._experimental_lower_tensor_list_ops = False\n"
     ]
    }
   ],
   "source": [
    "# Mobil veya düşük güçlü cihazlarda hız kazanmak için:\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Kayıtlı Keras modelini yükle\n",
    "model = tf.keras.models.load_model('tsl_action_model.h5')\n",
    "\n",
    "# Converter oluştur\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Dosyayı kaydet\n",
    "with open('tsl_action_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"TFLite modeli kaydedildi: tsl_action_model.tflite\")\n",
    "\n",
    "# Sonra gerçek-zamanlı script’te tflite_runtime ile yükleyip invoke() edin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a3d29-35c0-42ce-b3d7-82535ea9f104",
   "metadata": {},
   "source": [
    "### Arayüz Performans İyileştirmeleri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6c0e13-6a5d-40c3-b8d8-2d6607a8437b",
   "metadata": {},
   "source": [
    "#### 1. Video Çözünürlüğünü Düşür"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111fba09-624f-4661-bc9c-a0146534239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53367a1-efa1-4428-af8b-cc01adcc9ea6",
   "metadata": {},
   "source": [
    "#### 2.UI Rendering\n",
    "\n",
    "OpenCV yerine hafif bir GUI kütüphanesi (ör. PySimpleGUI) deneyin.\n",
    "\n",
    "Metin güncellemelerini sadece değişiklik olduğunda yeniden çizdirin.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9015efa4-ee85-4485-a438-77bd03773139",
   "metadata": {},
   "source": [
    "###  Gerçek Koşullarda Test\n",
    "\n",
    "#### 1.Farklı Işık/Açı Koşulları\n",
    "\n",
    "Aydınlık ve karanlık ortamda test edin.\n",
    "\n",
    "Arka plan karmaşık olduğunda doğruluğa bakın."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b831017d-62f3-472d-a052-5ea4d3bd5ab9",
   "metadata": {},
   "source": [
    "#### 2.Gerçek Kullanıcı Testi\n",
    "\n",
    "En az 5 kişi, her işaretten 10 tekrar yaparak test etsin.\n",
    "\n",
    "Yanlış sınıflandırmaları not ederek confusion matrix çıkarın:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c638fda-c9b1-459e-ba40-9daf52b7bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "y_true = y_test.argmax(axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52c38b2-0c41-43ee-8385-06d3843b1b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
